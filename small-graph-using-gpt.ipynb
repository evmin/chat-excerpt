{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Graph using text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain langchain-community langchain-openai langchain-experimental neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"companies that Elon Musk co-founded and subsidiary other company\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "#OpenAI\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
    "os.environ[\"AZURE_OPENAI_API_KEY\"] = \"\"\n",
    "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = \"\"\n",
    "os.environ[\"AZURE_OPENAI_API_VERSION\"] = \"2024-02-01\"\n",
    "os.environ[\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\"] = \"gpt4\"\n",
    "os.environ[\"AZURE_OPENAI_EMBEDING_MODEL\"] = \"text-embedding-ada-002\"\n",
    "#Search \n",
    "os.environ[\"AZURE_SEARCH_API_KEY\"] = \"\",\n",
    "os.environ[\"AZURE_SEARCH_ENDPOINT\"] = \"\"\n",
    "os.environ[\"AZURE_SEARCH_INDEX\"] = \"\"\n",
    "\n",
    "#Neo4j\n",
    "os.environ[\"NEO4J_URI\"] = \"bolt://54.146.136.117:7687\"\n",
    "os.environ[\"NEO4J_USERNAME\"] = \"test\"\n",
    "os.environ[\"NEO4J_PASSWORD\"] = \"password\"\n",
    "os.environ[\"NEO4J_DATABSE\"] = \"neo4j\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the database name to connect to\n",
    "from langchain_community.graphs import Neo4jGraph\n",
    "graph = Neo4jGraph(database=os.environ[\"NEO4J_DATABSE\"])\n",
    "\n",
    "from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "\n",
    "llm = AzureChatOpenAI(openai_api_version=os.environ[\"AZURE_OPENAI_API_VERSION\"],\n",
    "    azure_deployment=os.environ[\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\"])\n",
    "llm_transformer = LLMGraphTransformer(llm=llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File to Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wiki to Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WikipediaLoader\n",
    "\n",
    "query = \"Elon Musk\"\n",
    "raw_documents = WikipediaLoader(query=query).load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DiffbotGraphTransformer calls Diffbot Natural Language API to extract entities and relationships in the article\n",
    "from langchain_experimental.graph_transformers.diffbot import DiffbotGraphTransformer\n",
    "import os\n",
    "\n",
    "diffbot_api_key = \"\" \n",
    "\n",
    "diffbot_nlp = DiffbotGraphTransformer(diffbot_api_key=diffbot_api_key)\n",
    "\n",
    "# Diffbot's Natural Language API converts unstructured text data into knowlegde graphs\n",
    "graph_documents = diffbot_nlp.convert_to_graph_documents(raw_documents)\n",
    "\n",
    "# add knowledge graph data to the neo4j database\n",
    "graph.add_graph_documents(graph_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text to Graph example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodes:[Node(id='Marie Curie', type='Person'), Node(id='1867', type='Year'), Node(id='Polish', type='Nationality'), Node(id='Naturalised-French', type='Nationality'), Node(id='Physicist', type='Occupation'), Node(id='Chemist', type='Occupation'), Node(id='Radioactivity', type='Fieldofstudy'), Node(id='Nobel Prize', type='Award'), Node(id='Pierre Curie', type='Person'), Node(id='University Of Paris', type='Organization'), Node(id='1906', type='Year'), Node(id='Curie Family Legacy', type='Legacy'), Node(id='Five Nobel Prizes', type='Achievement')]\n",
      "Relationships:[Relationship(source=Node(id='Marie Curie', type='Person'), target=Node(id='1867', type='Year'), type='BORN_IN'), Relationship(source=Node(id='Marie Curie', type='Person'), target=Node(id='Polish', type='Nationality'), type='NATIONALITY'), Relationship(source=Node(id='Marie Curie', type='Person'), target=Node(id='Naturalised-French', type='Nationality'), type='NATIONALITY'), Relationship(source=Node(id='Marie Curie', type='Person'), target=Node(id='Physicist', type='Occupation'), type='OCCUPATION'), Relationship(source=Node(id='Marie Curie', type='Person'), target=Node(id='Chemist', type='Occupation'), type='OCCUPATION'), Relationship(source=Node(id='Marie Curie', type='Person'), target=Node(id='Radioactivity', type='Fieldofstudy'), type='RESEARCHED'), Relationship(source=Node(id='Marie Curie', type='Person'), target=Node(id='Nobel Prize', type='Award'), type='WON'), Relationship(source=Node(id='Marie Curie', type='Person'), target=Node(id='University Of Paris', type='Organization'), type='PROFESSOR'), Relationship(source=Node(id='Marie Curie', type='Person'), target=Node(id='1906', type='Year'), type='BECAME_PROFESSOR'), Relationship(source=Node(id='Pierre Curie', type='Person'), target=Node(id='Nobel Prize', type='Award'), type='WON'), Relationship(source=Node(id='Curie Family Legacy', type='Legacy'), target=Node(id='Five Nobel Prizes', type='Achievement'), type='CONSISTS_OF')]\n"
     ]
    }
   ],
   "source": [
    "#Convert Text to Vector Graph\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "text = \"\"\"\n",
    "Marie Curie, born in 1867, was a Polish and naturalised-French physicist and chemist who conducted pioneering research on radioactivity.\n",
    "She was the first woman to win a Nobel Prize, the first person to win a Nobel Prize twice, and the only person to win a Nobel Prize in two scientific fields.\n",
    "Her husband, Pierre Curie, was a co-winner of her first Nobel Prize, making them the first-ever married couple to win the Nobel Prize and launching the Curie family legacy of five Nobel Prizes.\n",
    "She was, in 1906, the first woman to become a professor at the University of Paris.\n",
    "\"\"\"\n",
    "documents = [Document(page_content=text)]\n",
    "graph_documents = llm_transformer.convert_to_graph_documents(documents)\n",
    "\n",
    "#result\n",
    "print(f\"Nodes:{graph_documents[0].nodes}\")\n",
    "print(f\"Relationships:{graph_documents[0].relationships}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodes:[Node(id='Marie Curie', type='Person'), Node(id='Pierre Curie', type='Person'), Node(id='Poland', type='Country'), Node(id='France', type='Country'), Node(id='University Of Paris', type='Organization')]\n",
      "Relationships:[Relationship(source=Node(id='Marie Curie', type='Person'), target=Node(id='Poland', type='Country'), type='NATIONALITY'), Relationship(source=Node(id='Marie Curie', type='Person'), target=Node(id='France', type='Country'), type='NATIONALITY'), Relationship(source=Node(id='Marie Curie', type='Person'), target=Node(id='Pierre Curie', type='Person'), type='SPOUSE'), Relationship(source=Node(id='Marie Curie', type='Person'), target=Node(id='University Of Paris', type='Organization'), type='WORKED_AT')]\n"
     ]
    }
   ],
   "source": [
    "# Graph Transformer Filtered\n",
    "llm_transformer_filtered = LLMGraphTransformer(\n",
    "    llm=llm,\n",
    "    allowed_nodes=[\"Person\", \"Country\", \"Organization\"],\n",
    "    allowed_relationships=[\"NATIONALITY\", \"LOCATED_IN\", \"WORKED_AT\", \"SPOUSE\"],\n",
    ")\n",
    "graph_documents_filtered = llm_transformer_filtered.convert_to_graph_documents(\n",
    "    documents\n",
    ")\n",
    "\n",
    "#result\n",
    "print(f\"Nodes:{graph_documents_filtered[0].nodes}\")\n",
    "print(f\"Relationships:{graph_documents_filtered[0].relationships}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodes:[Node(id='Marie Curie', type='Person', properties={'born_year': '1867'}), Node(id='Pierre Curie', type='Person'), Node(id='University Of Paris', type='Organization'), Node(id='Poland', type='Country'), Node(id='France', type='Country'), Node(id='Nobel Prize', type='Organization')]\n",
      "Relationships:[Relationship(source=Node(id='Marie Curie', type='Person'), target=Node(id='Poland', type='Country'), type='NATIONALITY'), Relationship(source=Node(id='Marie Curie', type='Person'), target=Node(id='France', type='Country'), type='NATIONALITY'), Relationship(source=Node(id='Marie Curie', type='Person'), target=Node(id='University Of Paris', type='Organization'), type='WORKED_AT'), Relationship(source=Node(id='Marie Curie', type='Person'), target=Node(id='Pierre Curie', type='Person'), type='SPOUSE'), Relationship(source=Node(id='Pierre Curie', type='Person'), target=Node(id='Nobel Prize', type='Organization'), type='WORKED_AT'), Relationship(source=Node(id='Marie Curie', type='Person'), target=Node(id='Nobel Prize', type='Organization'), type='WORKED_AT')]\n"
     ]
    }
   ],
   "source": [
    "# Graph Transformer Properties\n",
    "llm_transformer_props = LLMGraphTransformer(\n",
    "    llm=llm,\n",
    "    allowed_nodes=[\"Person\", \"Country\", \"Organization\"],\n",
    "    allowed_relationships=[\"NATIONALITY\", \"LOCATED_IN\", \"WORKED_AT\", \"SPOUSE\"],\n",
    "    node_properties=[\"born_year\"],\n",
    ")\n",
    "graph_documents_props = llm_transformer_props.convert_to_graph_documents(documents)\n",
    "\n",
    "#result\n",
    "print(f\"Nodes:{graph_documents_props[0].nodes}\")\n",
    "print(f\"Relationships:{graph_documents_props[0].relationships}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Graph\n",
    "graph.add_graph_documents(graph_documents_props)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Node properties:\\nPerson {positionHeld: STRING, academicDegree: STRING, id: STRING, name: STRING, age: STRING, dateOfBirth: STRING, numberOfChildren: STRING, causeOfDeath: STRING}\\nOrganization {id: STRING, name: STRING, foundingDate: STRING, productType: STRING}\\nSkill {name: STRING, id: STRING}\\nLocation {id: STRING, name: STRING}\\nAward {name: STRING, id: STRING}\\nRelationship properties:\\nEMPLOYEE_OR_MEMBER_OF {evidence: STRING, isCurrent: STRING, isNotCurrent: STRING, startTime: STRING, endTime: STRING, positionHeld: STRING}\\nHAS_CHILD {evidence: STRING}\\nFAMILY_MEMBER {evidence: STRING, isNotCurrent: STRING, startTime: STRING}\\nSOCIAL_RELATIONSHIP {evidence: STRING, isNotCurrent: STRING, startTime: STRING}\\nFOUNDED_BY {evidence: STRING}\\nACQUIRED_BY {evidence: STRING, pointInTime: STRING}\\nINDUSTRY {evidence: STRING}\\nGEOGRAPHIC_HERITAGE {evidence: STRING}\\nHAS_PARENT {evidence: STRING}\\nCHIEF_EXECUTIVE_OFFICER {evidence: STRING, isNotCurrent: STRING, isCurrent: STRING, endTime: STRING}\\nPLACE_OF_BIRTH {evidence: STRING}\\nPERSON_LOCATION {evidence: STRING, startTime: STRING, isNotCurrent: STRING, isCurrent: STRING}\\nPOLITICAL_AFFILIATION {evidence: STRING, isNotCurrent: STRING}\\nSIBLING {evidence: STRING}\\nEDUCATED_AT {evidence: STRING, isNotCurrent: STRING, endTime: STRING, isCurrent: STRING}\\nINTERESTED_IN {evidence: STRING}\\nFIELD_OF_WORK {evidence: STRING}\\nWORK_RELATIONSHIP {evidence: STRING}\\nCONTRIBUTED_TO {evidence: STRING}\\nNATIONALITY {evidence: STRING}\\nROMANTIC_RELATIONSHIP {evidence: STRING, isNotCurrent: STRING, startTime: STRING}\\nSPOUSE {evidence: STRING, isNotCurrent: STRING, startTime: STRING}\\nORGANIZATION_LOCATIONS {evidence: STRING, isCurrent: STRING, startTime: STRING, isNotCurrent: STRING}\\nBOARD_MEMBER {evidence: STRING, isCurrent: STRING, isNotCurrent: STRING, startTime: STRING, endTime: STRING}\\nSUBSIDIARY {evidence: STRING, startTime: STRING, isCurrent: STRING}\\nPARENT_ORGANIZATION {evidence: STRING, startTime: STRING, isCurrent: STRING}\\nAWARDS {evidence: STRING}\\nSTOCK_EXCHANGE {evidence: STRING, startTime: STRING}\\nAUTHOR_OF {evidence: STRING, pointInTime: STRING}\\nBRANDS {evidence: STRING}\\nThe relationships:\\n(:Person)-[:EMPLOYEE_OR_MEMBER_OF]->(:Organization)\\n(:Person)-[:FAMILY_MEMBER]->(:Person)\\n(:Person)-[:SOCIAL_RELATIONSHIP]->(:Person)\\n(:Person)-[:GEOGRAPHIC_HERITAGE]->(:Location)\\n(:Person)-[:GEOGRAPHIC_HERITAGE]->(:Organization)\\n(:Person)-[:HAS_PARENT]->(:Person)\\n(:Person)-[:PLACE_OF_BIRTH]->(:Location)\\n(:Person)-[:PERSON_LOCATION]->(:Location)\\n(:Person)-[:PERSON_LOCATION]->(:Organization)\\n(:Person)-[:SIBLING]->(:Person)\\n(:Person)-[:EDUCATED_AT]->(:Organization)\\n(:Person)-[:INTERESTED_IN]->(:Skill)\\n(:Person)-[:FIELD_OF_WORK]->(:Skill)\\n(:Person)-[:WORK_RELATIONSHIP]->(:Person)\\n(:Person)-[:NATIONALITY]->(:Location)\\n(:Person)-[:ROMANTIC_RELATIONSHIP]->(:Person)\\n(:Person)-[:SPOUSE]->(:Person)\\n(:Person)-[:HAS_CHILD]->(:Person)\\n(:Person)-[:POLITICAL_AFFILIATION]->(:Organization)\\n(:Person)-[:AWARDS]->(:Award)\\n(:Person)-[:CONTRIBUTED_TO]->(:Organization)\\n(:Person)-[:CONTRIBUTED_TO]->(:Location)\\n(:Person)-[:AUTHOR_OF]->(:Skill)\\n(:Organization)-[:FOUNDED_BY]->(:Person)\\n(:Organization)-[:CHIEF_EXECUTIVE_OFFICER]->(:Person)\\n(:Organization)-[:INDUSTRY]->(:Skill)\\n(:Organization)-[:ORGANIZATION_LOCATIONS]->(:Location)\\n(:Organization)-[:ACQUIRED_BY]->(:Organization)\\n(:Organization)-[:BOARD_MEMBER]->(:Person)\\n(:Organization)-[:SUBSIDIARY]->(:Organization)\\n(:Organization)-[:PARENT_ORGANIZATION]->(:Organization)\\n(:Organization)-[:BRANDS]->(:Organization)\\n(:Organization)-[:STOCK_EXCHANGE]->(:Organization)'"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.schema\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init LLM Search in Graph\n",
    "from langchain.chains import GraphCypherQAChain\n",
    "\n",
    "initial_context_from_knowledge_graph = GraphCypherQAChain.from_llm(\n",
    "    cypher_llm=llm, \n",
    "    qa_llm=llm, \n",
    "    graph=graph,\n",
    "    validate_cypher=True, \n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "> Entering new GraphCypherQAChain chain...\n",
      "Generated Cypher:\n",
      "cypher\n",
      "MATCH (p:Person {name: \"Elon Musk\"})-[:FOUNDED_BY]-(c:Organization)-[:SUBSIDIARY]->(s:Organization)\n",
      "RETURN c.name AS CompanyName, s.name AS SubsidiaryName\n",
      "\n",
      "Full Context:\n",
      "[{'CompanyName': 'SpaceX', 'SubsidiaryName': 'TBC - THE BORING COMPANY'}, {'CompanyName': 'OpenAI', 'SubsidiaryName': 'OpenAI Global, LLC'}]\n",
      "\n",
      "> Finished chain.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'SpaceX and OpenAI are companies that Elon Musk co-founded which have subsidiary companies. TBC - The Boring Company is a subsidiary of SpaceX, and OpenAI Global, LLC is a subsidiary of OpenAI.'"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Knowledge Graph Instructions and Query\n",
    "rules = \"\"\"\n",
    "# Knowledge Graph Instructions:\n",
    "## 1. Overview\n",
    "You are a top-tier algorithm designed for extracting information in structured formats to build a knowledge graph.\n",
    "- **Nodes** represent entities and concepts. They're akin to Wikipedia nodes.\n",
    "- The aim is to achieve simplicity and clarity in the knowledge graph, making it accessible for a vast audience.\n",
    "## 2. Labeling Nodes\n",
    "- **Consistency**: Ensure you use basic or elementary types for node labels.\n",
    "  - For example, when you identify an entity representing a person, always label it as **\"person\"**. Avoid using more specific terms like \"mathematician\" or \"scientist\".\n",
    "- **Node IDs**: Never utilize integers as node IDs. Node IDs should be names or human-readable identifiers found in the text.\n",
    "{'- **Allowed Node Labels:**' + \", \".join(allowed_nodes) if allowed_nodes else \"\"}\n",
    "{'- **Allowed Relationship Types**:' + \", \".join(allowed_rels) if allowed_rels else \"\"}\n",
    "## 3. Handling Numerical Data and Dates\n",
    "- Numerical data, like age or other related information, should be incorporated as attributes or properties of the respective nodes.\n",
    "- **No Separate Nodes for Dates/Numbers**: Do not create separate nodes for dates or numerical values. Always attach them as attributes or properties of nodes.\n",
    "- **Property Format**: Properties must be in a key-value format.\n",
    "- **Quotation Marks**: Never use escaped single or double quotes within property values.\n",
    "- **Naming Convention**: Use camelCase for property keys, e.g., `birthDate`.\n",
    "## 4. Coreference Resolution\n",
    "- **Maintain Entity Consistency**: When extracting entities, it's vital to ensure consistency.\n",
    "If an entity, such as \"John Doe\", is mentioned multiple times in the text but is referred to by different names or pronouns (e.g., \"Joe\", \"he\"), \n",
    "always use the most complete identifier for that entity throughout the knowledge graph. In this example, use \"John Doe\" as the entity ID.  \n",
    "Remember, the knowledge graph should be coherent and easily understandable, so maintaining consistency in entity references is crucial. \n",
    "\"\"\"\n",
    "question_neuralink_industry = f\"{query}, {rules}\"\n",
    "kg_context = initial_context_from_knowledge_graph.run(question_neuralink_industry)\n",
    "kg_context\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Go to WIKI - Collect and Embed - if not using Azure Search - Using Chroma - Using DSPY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\liorarmiev\\Documents\\ai\\GraphRag\\dspy\\.venv\\Lib\\site-packages\\wikipedia\\wikipedia.py:389: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"html.parser\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 389 of the file c:\\Users\\liorarmiev\\Documents\\ai\\GraphRag\\dspy\\.venv\\Lib\\site-packages\\wikipedia\\wikipedia.py. To get rid of this warning, pass the additional argument 'features=\"html.parser\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  lis = BeautifulSoup(html).find_all('li')\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import WikipediaLoader\n",
    "\n",
    "query = \"Elon Musk\"\n",
    "raw_documents = WikipediaLoader(query=query).load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "\n",
    "# Split\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=512, chunk_overlap=100\n",
    ")\n",
    "all_splits = text_splitter.split_documents(raw_documents)\n",
    "\n",
    "import chromadb.utils.embedding_functions as embedding_functions\n",
    "embeddings = AzureOpenAIEmbeddings(model=\"text-embedding-ada-002\", azure_endpoint=\"https://lioropenaitest.openai.azure.com/\", api_key=\"dc7032d007034a0c99db583e0726d41a\", api_version=\"2024-02-01\")\n",
    "\n",
    "CHROMA_COLLECTION_NAME = \"dspy-rag-chroma\"\n",
    "CHROMADB_DIR = \"dspy_rag_chroma/\"\n",
    "\n",
    "# Index\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=all_splits,\n",
    "    collection_name=CHROMA_COLLECTION_NAME,\n",
    "    embedding=embeddings,\n",
    "    persist_directory=CHROMADB_DIR\n",
    ")\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\liorarmiev\\Documents\\ai\\GraphRag\\dspy\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "vectorstore.persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from chromadb.utils.embedding_functions import OpenAIEmbeddingFunction\n",
    "from dspy.retrieve.chromadb_rm import ChromadbRM\n",
    "import os\n",
    "\n",
    "embedding_function = OpenAIEmbeddingFunction(\n",
    "    api_key=os.environ.get('OPENAI_API_KEY'),\n",
    "    model_name=os.environ.get('AZURE_OPENAI_EMBEDING_MODEL'),\n",
    "    api_version=os.environ.get('AZURE_OPENAI_API_VERSION'),\n",
    "    api_base=os.environ.get('AZURE_OPENAI_ENDPOINT'),\n",
    ")\n",
    "\n",
    "rm = ChromadbRM(CHROMA_COLLECTION_NAME, CHROMADB_DIR, embedding_function, k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dspy\n",
    "from dspy.retrieve.chromadb_rm import ChromadbRM\n",
    "\n",
    "class GenerateAnswer(dspy.Signature):\n",
    "    \"\"\"Answer questions with short factoid answers.\"\"\"\n",
    "\n",
    "    context = dspy.InputField(desc=\"may contain relevant facts\")\n",
    "    question = dspy.InputField()\n",
    "    answer = dspy.OutputField(desc=\"often between 1 and 5 words\")\n",
    "\n",
    "#vanilla_dspy_rag_lm = dspy.OpenAI(model='gpt-3.5-turbo-instruct')\n",
    "#vanilla_dspy_rag_lm = dspy.AzureOpenAI(model=\"gpt35\", api_base=\"https://lioropenaitest.openai.azure.com/\", api_key=\"dc7032d007034a0c99db583e0726d41a\", api_version=\"2024-02-01\")\n",
    "dspy.settings.configure(lm=llm, rm=rm)\n",
    "\n",
    "class vanilla_dspy_rag(dspy.Module):\n",
    "    \n",
    "    # we set num_passages=1 to avoid the same passage being repeatedly retrieved for multiple times\n",
    "    def __init__(self, num_passages=1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.retrieve = dspy.Retrieve(k=num_passages)\n",
    "        self.generate_answer = dspy.ChainOfThought(GenerateAnswer)\n",
    "    \n",
    "    def forward(self, question):\n",
    "        context = self.retrieve(question).passages\n",
    "        prediction = self.generate_answer(context=context, question=question)\n",
    "        return dspy.Prediction(context=context, answer=prediction.answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_neuralink_industry = 'What industry or industries is Neuralink in?'\n",
    "#vector quary the chroma db using the question\n",
    "vanilla_dspy_rag(question_neuralink_industry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Azure Vecotr Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.search.documents import SearchClient\n",
    "from azure.search.documents.indexes import SearchIndexClient\n",
    "from azure.search.documents.models import VectorizedQuery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "service_endpoint = os.environ[\"AZURE_SEARCH_ENDPOINT\"]\n",
    "index_name = os.environ[\"AZURE_SEARCH_INDEX\"]\n",
    "key = os.environ[\"AZURE_SEARCH_API_KEY\"]\n",
    "\n",
    "def get_embeddings(text: str):\n",
    "    # There are a few ways to get embeddings. This is just one example.\n",
    "    import openai\n",
    "\n",
    "    open_ai_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "    open_ai_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "    client = openai.AzureOpenAI(\n",
    "        azure_endpoint=open_ai_endpoint,\n",
    "        api_key=open_ai_key,\n",
    "        api_version=os.getenv(\"AZURE_OPENAI_API_VERSION\"),\n",
    "    )\n",
    "    embedding = client.embeddings.create(input=[text], model=os.getenv(\"AZURE_OPENAI_EMBEDING_MODEL\"))\n",
    "    return embedding.data[0].embedding\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'content': \"he made from the sale of PayPal, Musk founded SpaceX, a spaceflight services company, in 2002. \\nIn 2004, Musk became an early investor in electric vehicle manufacturer Tesla Motors, Inc. (later Tesla, Inc.). He became the company's chairman and product architect, assuming the position of CEO in 2008. In 2006, Musk helped create SolarCity, a solar-energy company that was acquired by Tesla in 2016 and became Tesla Energy. In 2013, he proposed a hyperloop high-speed vactrain transportation system. In 2015, he co-founded OpenAI, a nonprofit artificial intelligence research company. The following year, Musk co-founded Neuralink—a neurotechnology company developing brain–computer interfaces—and the Boring Company, a tunnel construction company.\", 'id': 'aHR0cHM6Ly9zdHJpbWtjbGZsaGQzeW1hLmJsb2IuY29yZS53aW5kb3dzLm5ldC9kb2N1bWVudHMvaHR0cHM6Ly9lbi53aWtpcGVkaWEub3JnL3dpa2kvRWxvbl9NdXNr0', '@search.score': 0.88719743, '@search.reranker_score': None, '@search.highlights': None, '@search.captions': None}\n",
      "{'content': 'company developing brain–computer interfaces—and the Boring Company, a tunnel construction company. In 2018, the U.S. Securities and Exchange Commission (SEC) sued Musk, alleging that he had falsely announced that he had secured funding for a private takeover of Tesla. To settle the case, Musk stepped down as the chairman of Tesla and paid a $20 million fine. In 2022, he acquired Twitter for $44\\xa0billion. He subsequently merged the company into newly created X Corp. and rebranded the service as X the following year. In March 2023, Musk founded xAI, an artificial intelligence company.\\nMusk has expressed views that have made him a polarizing figure.', 'id': 'aHR0cHM6Ly9zdHJpbWtjbGZsaGQzeW1hLmJsb2IuY29yZS53aW5kb3dzLm5ldC9kb2N1bWVudHMvaHR0cHM6Ly9lbi53aWtpcGVkaWEub3JnL3dpa2kvRWxvbl9NdXNr0', '@search.score': 0.87175274, '@search.reranker_score': None, '@search.highlights': None, '@search.captions': None}\n",
      "{'content': 'States\\nEducationUniversity of Pennsylvania (BA, BS)Title\\nFounder, CEO, and chief engineer of SpaceX\\nCEO and product architect of Tesla, Inc.\\nOwner, CTO and Executive Chairman of X (formerly Twitter)\\nPresident of the Musk Foundation\\nFounder of The Boring Company, X Corp., and xAI\\nCo-founder of Neuralink, OpenAI, Zip2, and X.com (part of PayPal)\\nSpouses\\nJustine Wilson\\n\\u200b \\u200b(m.\\xa02000; div.\\xa02008)\\u200b\\nTalulah Riley\\n\\u200b \\u200b(m.\\xa02010; div.\\xa02012)\\u200b \\n\\u200b\\n \\u200b(m.\\xa02013; div.\\xa02016)\\u200bPartnersGrimes (2018–2021)[1]Children11[a][3]ParentsErrol MuskMaye MuskRelatives\\nKimbal Musk (brother)\\nTosca Musk (sister)\\nLyndon Rive (cousin)\\nFamilyMusk familySignature\\n\\n\\nThis article is part of a series aboutElon Musk\\n\\nAwards and honors\\nViews\\nFilmography\\n\\nCompanies\\nZip2\\nX.com PayPal\\nSpaceX Starlink', 'id': 'aHR0cHM6Ly9zdHJpbWtjbGZsaGQzeW1hLmJsb2IuY29yZS53aW5kb3dzLm5ldC9kb2N1bWVudHMvaHR0cHM6Ly9lbi53aWtpcGVkaWEub3JnL3dpa2kvRWxvbl9NdXNr0', '@search.score': 0.865943, '@search.reranker_score': None, '@search.highlights': None, '@search.captions': None}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "search_client = SearchClient(service_endpoint, index_name, AzureKeyCredential(key))\n",
    "vector_query = VectorizedQuery(vector=get_embeddings(query), k_nearest_neighbors=3, fields=\"content_vector\")\n",
    "\n",
    "results = search_client.search(\n",
    "    vector_queries=[vector_query],\n",
    "    select=[\"id\", \"content\"],\n",
    ")\n",
    "\n",
    "result_array = []\n",
    "for result in results:\n",
    "    print(result)\n",
    "    result_array.append(result)\n",
    "# [END single_vector_search]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_client = SearchClient(service_endpoint, index_name, AzureKeyCredential(key))\n",
    "vector_query = VectorizedQuery(vector=get_embeddings(query), k_nearest_neighbors=3, fields=\"content_vector\")\n",
    "\n",
    "results = search_client.search(\n",
    "    search_text=query,\n",
    "    vector_queries=[vector_query],\n",
    "    select=[\"id\", \"content\"],\n",
    ")\n",
    "\n",
    "for result in results:\n",
    "    print(result)\n",
    "# [END simple_hybrid_search]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM Answer (No data sources)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_core.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    ")\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elon Musk co-founded companies like Zip2, PayPal, SpaceX, Tesla, Inc., Neuralink, and The Boring Company; Tesla's subsidiary includes SolarCity.\n"
     ]
    }
   ],
   "source": [
    "chat = llm\n",
    "\n",
    "# Vector Search Answer\n",
    "messages = [\n",
    "    SystemMessage(\n",
    "        content=f\"You are a helpful assistant who generates information to questions. Please answer the question\"\n",
    "    ),\n",
    "    HumanMessage(\n",
    "        content= f\"{query}\"\n",
    "    ),\n",
    "    HumanMessage(\n",
    "        content= f\"write a short answer based on the information above, provide a short answer, not nore than 1 line that must answer the question.\"\n",
    "    )\n",
    "    \n",
    "]\n",
    "LLM_ans_colleague = chat.invoke(messages)\n",
    "print(LLM_ans_colleague.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vector LLM answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print the Question\n",
    "print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elon Musk co-founded and is involved with companies such as SpaceX, Tesla, Inc., SolarCity (now Tesla Energy), Neuralink, The Boring Company, OpenAI, and he acquired Twitter, which was later integrated into X Corp.\n"
     ]
    }
   ],
   "source": [
    "chat = llm\n",
    "\n",
    "# Vector Search Answer\n",
    "messages = [\n",
    "    SystemMessage(\n",
    "        content=f\"You are a helpful assistant who generates information grounded with facts. Please enhance Vector search answer and generate the final answer. the question was: {query}\"\n",
    "    ),\n",
    "    HumanMessage(\n",
    "        content= f\"Search Results: {result_array}\"\n",
    "    ),\n",
    "    HumanMessage(\n",
    "        content= f\"write a short answer based on the information above, provide a short answer, not nore than 1 line that must answer the question.\"\n",
    "    )\n",
    "    \n",
    "]\n",
    "vector_ans_colleague = chat.invoke(messages)\n",
    "print(vector_ans_colleague.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boom!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elon Musk co-founded companies such as SpaceX, Tesla, Inc., SolarCity, OpenAI, Neuralink, and The Boring Company, with SpaceX owning The Boring Company as a subsidiary and OpenAI Global, LLC being a subsidiary of OpenAI.\n"
     ]
    }
   ],
   "source": [
    "chat = llm\n",
    "\n",
    "# Full Answer Graph and Vector Search\n",
    "messages = [\n",
    "    SystemMessage(\n",
    "        content=f\"You are a helpful assistant who generates information grounded with facts. Please enhance the original answer with complementary entity and relationship information from the knowledge graph to generate the final answer. the question was: {query}\"\n",
    "    ),\n",
    "    HumanMessage(\n",
    "        content= f\"Graph Results: {kg_context}\"\n",
    "    ),\n",
    "    HumanMessage(\n",
    "        content= f\"Search Results: {result_array}\"\n",
    "    ),\n",
    "    HumanMessage(\n",
    "        content= f\"write a short answer based on the information above, provide a short answer, not nore than 1 line that must answer the question.\"\n",
    "    )\n",
    "    \n",
    "]\n",
    "final_ans_colleague = chat.invoke(messages)\n",
    "print(final_ans_colleague.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
